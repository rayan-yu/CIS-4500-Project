# -*- coding: utf-8 -*-
"""preprocessing.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1bzYYhHEIeczR6K4t2K1Ds8ChhU9F-lKr

# Pre-processing Tutorial

## Introduction

*   Removal of rows with missing values
*   Replacement of missing values with default values
*   Dectection of entity resolution problems
*   Simple entity resolution
*   Removal of unpaired entities
*   Replacement of categorical variables with indicators
*   Identification of candidate indices
*   Data exportation

## Setup

Run the cell below to import necessary modules.
"""

import numpy as np
import pandas as pd
from google.colab import drive

"""
To prepare the datasets for ingestion into the database, we need to:
1. Clean missing / misentered values
2. Detect and solve entity resolution problems
3. Replace categorical variables with numeric indicators for efficiency
4. Export the data

Before doing any of this, we need to import the datasets to _pandas_ `DataFrames`. We'll follow the data importation procedure outlined in the [EDA tutorial](https://drive.google.com/open?id=1Cy3izai9zLQYTCTQF9IwkcuLmNArcKZO). Add the datasets to your Google Drive using the links above, then mount your Drive to the notebook by running the cell below."""

prefix = '/content/drive'
from google.colab import drive
drive.mount(prefix, force_remount=True)

"""Finally, run the cell below to load the census data into a `DataFrame` named `census` and the life expectancy data into a `DataFrame` named `le`."""

s_bundesliga = pd.read_csv("/content/drive/My Drive/trades_data/1-bundesliga.csv")
s_champ = pd.read_csv("/content/drive/My Drive/trades_data/championship.csv")
s_eredivisie = pd.read_csv("/content/drive/My Drive/trades_data/eredivisie.csv")
s_liganos = pd.read_csv("/content/drive/My Drive/trades_data/liga-nos.csv")
s_ligue1 = pd.read_csv("/content/drive/My Drive/trades_data/ligue-1.csv")
s_premierleague = pd.read_csv("/content/drive/My Drive/trades_data/premier-league.csv")
s_premierliga = pd.read_csv("/content/drive/My Drive/trades_data/premier-liga.csv")
s_primeradiv = pd.read_csv("/content/drive/My Drive/trades_data/primera-division.csv")
s_seriea = pd.read_csv("/content/drive/My Drive/trades_data/serie-a.csv")

t_appearances = pd.read_csv("/content/drive/My Drive/transfermarkt_data/appearances.csv")
t_clubgames = pd.read_csv("/content/drive/My Drive/transfermarkt_data/club_games.csv")
t_clubs = pd.read_csv("/content/drive/My Drive/transfermarkt_data/clubs.csv")
t_comps = pd.read_csv("/content/drive/My Drive/transfermarkt_data/competitions.csv")
t_events = pd.read_csv("/content/drive/My Drive/transfermarkt_data/game_events.csv")
t_games = pd.read_csv("/content/drive/My Drive/transfermarkt_data/games.csv")
t_playerval = pd.read_csv("/content/drive/My Drive/transfermarkt_data/player_valuations.csv")
t_players = pd.read_csv("/content/drive/My Drive/transfermarkt_data/players.csv")

"""## Clean Missing Values

1. Clubs.csv: remove rows with no club name, create new column called “transfer_euros” with cleaned net_transfer_record data (remove currency symbol, replace abbreviations with appropriate multiple)
2. Players.csv: for the players who are known by a single name (empty first name), replace the empty first name with the entry in last name and replace the last name entry with “”
3. all trades .csv files replace ‘NA’ in fee_cleaned with -1, since there is no negative fee values in the column and we have a column referring to if the fee transfer amount is in/out
"""

def convert_transfer(record):
    if record == "+-0":
        return 0
    elif 'm' in record:
        return float(record.replace('€', '').replace('m', '')) * 1e6
    elif 'k' in record:
        return float(record.replace('€', '').replace('k', '')) * 1e3
    else:
        return float(record.replace('€', ''))

t_clubs = t_clubs[t_clubs["name"].notna()] #remove rows without country
t_clubs = t_clubs.drop(columns =['total_market_value', 'coach_name'])

t_clubs['transfer_euros'] = t_clubs['net_transfer_record'].apply(convert_transfer)
t_clubs

t_players['single'] = (t_players['first_name'].isnull()) & ~(t_players['last_name'].isnull())

t_players['first_name'] = t_players.apply(lambda row: row['last_name'] if row['single'] else row['first_name'], axis=1)
t_players['last_name'] = t_players.apply(lambda row: '' if row['single'] else row['last_name'], axis=1)

t_players = t_players[~(t_players['first_name'].isnull() & t_players['last_name'].isnull())]
t_players = t_players.drop(columns =['single'])
t_players

s_bundesliga['fee_cleaned'].fillna(-1, inplace=True)
s_champ['fee_cleaned'].fillna(-1, inplace=True)
s_eredivisie['fee_cleaned'].fillna(-1, inplace=True)
s_liganos['fee_cleaned'].fillna(-1, inplace=True)
s_ligue1['fee_cleaned'].fillna(-1, inplace=True)
s_premierleague['fee_cleaned'].fillna(-1, inplace=True)
s_premierliga['fee_cleaned'].fillna(-1, inplace=True)
s_primeradiv['fee_cleaned'].fillna(-1, inplace=True)
s_seriea['fee_cleaned'].fillna(-1, inplace=True)

s_bundesliga

"""## Entity Resolution

Now that we've handled missing values in both datasets, we turn our attention to performing entity resolution on the entities common to both. In this case, those common entities are countries.

To perform entity resolution, we will:
1. Determine whether both datasets use the same names to refer to all countries
2. Edit the names in one dataset to match the other, if necessary

In the general case, you may also need to detect when datasets refer to different entities using the same name/ID and disambiguate these references. This may happen when handling datasets that contain multiple people with the same name, for example. But we don't need to worry about it here because the names of countries are well-known and distict.

### Detect Inconsistent Names
Let's compile a list of all country names in both datasets, then inspect it for repetitions.

First, we extract the unique names of countries from both datasets.
"""

#find club names datasets

bundsliga_names = s_bundesliga["club_name"].unique()
champ_names = s_champ["club_name"].unique()
eredivisie_names = s_eredivisie["club_name"].unique()
liganos_names = s_liganos["club_name"].unique()
ligue1_names = s_ligue1["club_name"].unique()
premierleague_names = s_premierleague["club_name"].unique()
premierliga_names = s_premierliga["club_name"].unique()
primeradiv_names = s_primeradiv["club_name"].unique()
seria_names = s_seriea["club_name"].unique()

s_names = set(bundsliga_names.tolist() + champ_names.tolist() + eredivisie_names.tolist() + liganos_names.tolist() + ligue1_names.tolist() + premierleague_names.tolist() + premierliga_names.tolist() + primeradiv_names.tolist() + seria_names.tolist())

t_names = set(t_clubs["name"].unique())

"""Now, we combine these into one set."""

#find set difference in club names

result_set = s_names.symmetric_difference(t_names)
result_set

import re

def revise_string(s):
    #remove hypens
    s = s.replace('-', ' ')
    #remove anything in parenthesis, including the parentheses
    s = re.sub(r'\([^)]*\)', '', s)
    #remove all numbers
    s = re.sub(r'\d+', '', s)
    #remove periods
    s = s.replace('.', '')
    #remove double spaces
    s = re.sub(r'\s+', ' ', s)
    #remove extra spaces at the front and end
    s = s.strip()
    return s

revised_s_names = {revise_string(s) for s in s_names}
revised_t_names = {revise_string(s) for s in t_names}
result_set2 = revised_s_names.symmetric_difference(revised_t_names)
result_set2

t_clubs['name'] = t_clubs['name'].apply(revise_string)
s_bundesliga['club_name'] = s_bundesliga['club_name'].apply(revise_string)
s_champ['club_name'] = s_champ['club_name'].apply(revise_string)
s_eredivisie['club_name'] = s_eredivisie['club_name'].apply(revise_string)
s_liganos['club_name'] = s_liganos['club_name'].apply(revise_string)
s_ligue1['club_name'] = s_ligue1['club_name'].apply(revise_string)
s_premierleague['club_name'] = s_premierleague['club_name'].apply(revise_string)
s_premierliga['club_name'] = s_premierliga['club_name'].apply(revise_string)
s_primeradiv['club_name'] = s_primeradiv['club_name'].apply(revise_string)
s_seriea['club_name'] = s_seriea['club_name'].apply(revise_string)

"""The output contains clubs with multiple names:

*   'Saturn REN TV Ramenskoe' and 'Saturn Ramenskoe'
*   'Spartak Alania Vladikavkaz' and 'Spartak Vladikavkaz'
*   'Genoa' and 'Genoa CFC'
*   'FC Nizhniy Novgorod' and 'FC Pari Nizhniy Novgorod'

### Resolve Inconsistent Names

We first create a `Series` of the countries with multiple names, where of each element is the name we'll purge, and the value is name we'll keep.
"""

name_map = {
    'Saturn Ramenskoe' : 'Saturn REN TV Ramenskoe',
    'Spartak Vladikavkaz' : 'Spartak Alania Vladikavkaz',
    'Genoa' : 'Genoa CFC',
    'FC Nizhniy Novgorod' : 'FC Pari Nizhniy Novgorod',
}
name_series = pd.Series(data=list(name_map.values()), index=list(name_map.keys()))
name_series

"""Next, we find the indices of all usages of the names we're purging in both datasets"""

purge_list = list(name_map.keys())

t_idx = t_clubs.index[t_clubs["name"].isin(purge_list)]
s_bundesliga_idx = s_bundesliga.index[s_bundesliga["club_name"].isin(purge_list)]
s_champ_idx = s_champ.index[s_champ["club_name"].isin(purge_list)]
s_eredivisie_idx = s_eredivisie.index[s_eredivisie["club_name"].isin(purge_list)]
s_liganos_idx = s_liganos.index[s_liganos["club_name"].isin(purge_list)]
s_ligue1_idx = s_ligue1.index[s_ligue1["club_name"].isin(purge_list)]
s_premierleague_idx = s_premierleague.index[s_premierleague["club_name"].isin(purge_list)]
s_premierliga_idx = s_premierliga.index[s_premierliga["club_name"].isin(purge_list)]
s_primeradiv_idx = s_primeradiv.index[s_primeradiv["club_name"].isin(purge_list)]
s_seriea_idx = s_seriea.index[s_seriea["club_name"].isin(purge_list)]

"""Using these indices, we extract the names that we need to update as `Series`"""

t_problems = t_clubs.loc[t_idx, "name"]
s_bundesliga_problems = s_bundesliga.loc[s_bundesliga_idx, "club_name"]
s_champ_problems = s_champ.loc[s_champ_idx, "club_name"]
s_eredivisie_problems = s_eredivisie.loc[s_eredivisie_idx, "club_name"]
s_liganos_problems = s_liganos.loc[s_liganos_idx, "club_name"]
s_ligue1_problems = s_ligue1.loc[s_ligue1_idx, "club_name"]
s_premierleague_problems = s_premierleague.loc[s_premierleague_idx, "club_name"]
s_premierliga_problems = s_premierliga.loc[s_premierliga_idx, "club_name"]
s_primeradiv_problems = s_primeradiv.loc[s_primeradiv_idx, "club_name"]
s_seriea_problems = s_seriea.loc[s_seriea_idx, "club_name"]

"""Next, we replace the problematic names in these `Series` with the appropriate counterparts by indexing `name_series` with them.

*The operations in the cell below replace the names correctly because `name_series` maps each name we wanted to purge to the we wanted to replace it with.*
"""

t_fixed = name_series.loc[t_problems.values].values
s_bundesliga_fixed = name_series.loc[s_bundesliga_problems.values].values
s_champ_fixed = name_series.loc[s_champ_problems.values].values
s_eredivisie_fixed = name_series.loc[s_eredivisie_problems.values].values
s_liganos_fixed = name_series.loc[s_liganos_problems.values].values
s_ligue1_fixed = name_series.loc[s_ligue1_problems.values].values
s_premierleague_fixed = name_series.loc[s_premierleague_problems.values].values
s_premierliga_fixed = name_series.loc[s_premierliga_problems.values].values
s_primeradiv_fixed = name_series.loc[s_primeradiv_problems.values].values
s_seriea_fixed = name_series.loc[s_seriea_problems.values].values

"""Finally, we update the dataframes with the fixed names."""

t_clubs.loc[t_idx, "name"] = t_fixed
s_bundesliga.loc[s_bundesliga_idx, "club_name"] = s_bundesliga_fixed
s_champ.loc[s_champ_idx, "club_name"] = s_champ_fixed
s_eredivisie.loc[s_eredivisie_idx, "club_name"] = s_eredivisie_fixed
s_liganos.loc[s_liganos_idx, "club_name"] = s_liganos_fixed
s_ligue1.loc[s_ligue1_idx, "club_name"] = s_ligue1_fixed
s_premierleague.loc[s_premierleague_idx, "club_name"] = s_premierleague_fixed
s_premierliga.loc[s_premierliga_idx, "club_name"] = s_premierliga_fixed
s_primeradiv.loc[s_primeradiv_idx, "club_name"] = s_primeradiv_fixed
s_seriea.loc[s_seriea_idx, "club_name"] = s_seriea_fixed

"""### Remove Unpaired Entities
In some cases, you may want to exclude entities that only appear in one dataset or the other from your database. Let's suppose that's the case here and remove all countries that only appear in one dataset or the other.

As before, we first extract the full list of countries found in both datasets and convert the lists to sets.
"""

bundsliga_names = s_bundesliga["club_name"].unique()
champ_names = s_champ["club_name"].unique()
eredivisie_names = s_eredivisie["club_name"].unique()
liganos_names = s_liganos["club_name"].unique()
ligue1_names = s_ligue1["club_name"].unique()
premierleague_names = s_premierleague["club_name"].unique()
premierliga_names = s_premierliga["club_name"].unique()
primeradiv_names = s_primeradiv["club_name"].unique()
seria_names = s_seriea["club_name"].unique()

s_names = set(bundsliga_names.tolist() + champ_names.tolist() + eredivisie_names.tolist() + liganos_names.tolist() + ligue1_names.tolist() + premierleague_names.tolist() + premierliga_names.tolist() + primeradiv_names.tolist() + seria_names.tolist())

t_names = set(t_clubs["name"].unique().tolist())

"""Then, we convert these lists to sets and use set-difference operations to find the countries that only appear in one set."""

t_diff = t_names.difference(s_names)
s_diff = s_names.difference(t_names)
total_diff = list(t_diff) + list(s_diff)

"""Finally, we drop all rows from both datasets that contain countries that match any of the countries in this list."""

t_clubs = t_clubs.loc[~t_clubs["name"].isin(total_diff), :]
s_bundesliga = s_bundesliga.loc[~s_bundesliga["club_name"].isin(total_diff), :]
s_champ = s_champ.loc[~s_champ["club_name"].isin(total_diff), :]
s_eredivisie = s_eredivisie.loc[~s_eredivisie["club_name"].isin(total_diff), :]
s_liganos = s_liganos.loc[~s_liganos["club_name"].isin(total_diff), :]
s_ligue1 = s_ligue1.loc[~s_ligue1["club_name"].isin(total_diff), :]
s_premierleague = s_premierleague.loc[~s_premierleague["club_name"].isin(total_diff), :]
s_premierliga = s_premierliga.loc[~s_premierliga["club_name"].isin(total_diff), :]
s_primeradiv = s_primeradiv.loc[~s_primeradiv["club_name"].isin(total_diff), :]
s_seriea = s_seriea.loc[~s_seriea["club_name"].isin(total_diff), :]

"""## Replace Categorical Variables with Indicators

First, we create a `Series` that maps each country name to an integer.
"""

combined_names = sorted(s_names | t_names)
name_codes = pd.Series(index=combined_names, data=np.arange(len(combined_names)))
name_codes

"""Next, we use this `Series` to map all countries in both datasets to the corresponding integers by indexing the `Series` with the names of the countries in the datasets."""

t_clubs["name"] = name_codes.loc[t_clubs["name"]].values
s_bundesliga["club_name"] = name_codes.loc[s_bundesliga["club_name"]].values
s_champ["club_name"] = name_codes.loc[s_champ["club_name"]].values
s_eredivisie["club_name"] = name_codes.loc[s_eredivisie["club_name"]].values
s_liganos["club_name"] = name_codes.loc[s_liganos["club_name"]].values
s_ligue1["club_name"] = name_codes.loc[s_ligue1["club_name"]].values
s_premierleague["club_name"] = name_codes.loc[s_premierleague["club_name"]].values
s_premierliga["club_name"] = name_codes.loc[s_premierliga["club_name"]].values
s_primeradiv["club_name"] = name_codes.loc[s_primeradiv["club_name"]].values
s_seriea["club_name"] = name_codes.loc[s_seriea["club_name"]].values

"""Finally, we convert the columns to integer types."""

t_clubs["name"] = t_clubs["name"].astype(np.int64)
s_bundesliga["club_name"] = s_bundesliga["club_name"].astype(np.int64)
s_champ["club_name"] = s_champ["club_name"].astype(np.int64)
s_eredivisie["club_name"] = s_eredivisie["club_name"].astype(np.int64)
s_liganos["club_name"] = s_liganos["club_name"].astype(np.int64)
s_ligue1["club_name"] = s_ligue1["club_name"].astype(np.int64)
s_premierleague["club_name"] = s_premierleague["club_name"].astype(np.int64)
s_premierliga["club_name"] = s_premierliga["club_name"].astype(np.int64)
s_primeradiv["club_name"] = s_primeradiv["club_name"].astype(np.int64)
s_seriea["club_name"] = s_seriea["club_name"].astype(np.int64)

"""## Find an Index

Before ingesting our data into the database, we need to find a unique index for each table

### Single-Column Index
"""

len(t_clubs["name"].unique()) == len(t_clubs["name"])

"""### Multi-Column Index

When there's not an individual column that can act as an index, we search for combinations of columns that can make a unique index when combined.

To check a candidate set of columns:
1. Call `DataFrame.groupby()` on the list of candidate columns. *This creates a group of rows for each unique combination of candidate olumn values that appears in the Dataframe*
2. Call `GroupBy.size()` on the resulting grouped dataframe. *This counts the number of rows in each group*
3. Check whether every group has exactly 1 row.

We use this procedure below to check whether `country` and `year` can function as a joint index.
"""

# Step 1: Group dataframe by candidate columns
grouped_le = le.groupby(["country", "year"])
# Step 2: Count rows in each group
counts = grouped_le.size()
print(counts)
# Step 3: Check whether every value equals 1
(counts == 1).all()

"""Great! This means no country-year pair appears more than once in the life expectancy table, so we can use `country` and `year` in combination as the index.

For the census dataset, you'd need every column to create a unique index (Check this for yourself). So we'll just plan to use the arbitrary, unique integers `census.index` as our table index.

## Export Data
After cleaning our datasets, resolving entity resolution problems, and choosing indices, we're ready to ingest our the data into our database.

In the past, students have found using Python for data ingestion slow and frustrating, so we won't populate the database here. Instead, we'll export both datasets and the country codes to CSVs. Then, we'll show you how to ingest these CSVs into your database using MySQL Workbench in the tutorial on data ingestion.

First, convert the `Series` of country codes to an equivalent `DataFrame`
"""

name_codes = pd.DataFrame(data={'name': name_codes.index, 'code': name_codes.values})

"""Next, we use `DataFrame.to_csv` to write each dataset to a CSV file with a descriptive name.

*For `le` and `country_codes`, we set `index` to `False` because the indices of the `DataFrames` are meaningless integers that we don't need in our tables. For `census`, we rename the index and include it in the output because we decided  to use it as our table index, even though it's arbitrary.*
"""

t_clubs.to_csv("t_clubs.csv", index=False)
t_players.to_csv("t_players.csv", index=False)
s_bundesliga.to_csv("s_bundesliga.csv", index=False)
s_champ.to_csv("s_champ.csv", index=False)
s_eredivisie.to_csv("s_eredivisie.csv", index=False)
s_liganos.to_csv("s_liganos.csv", index=False)
s_ligue1.to_csv("s_ligue1.csv", index=False)
s_premierleague.to_csv("s_premierleague.csv", index=False)
s_premierliga.to_csv("s_premierliga.csv", index=False)
s_primeradiv.to_csv("s_primeradiv.csv", index=False)
s_seriea.to_csv("s_seriea.csv", index=False)

name_codes.to_csv("name_codes.csv", index=False)

"""Finally, we download these files to our local machine, so we can put them into MySQL Workbench later."""

from google.colab import files
files.download("t_clubs.csv")
files.download("t_players.csv")
files.download("s_bundesliga.csv")
files.download("s_champ.csv")
files.download("s_eredivisie.csv")
files.download("s_liganos.csv")
files.download("s_ligue1.csv")
files.download("s_premierleague.csv")
files.download("s_premierliga.csv")
files.download("s_primeradiv.csv")
files.download("s_seriea.csv")

files.download("name_codes.csv")

"""## Exercises
Check out [these exercises](https://drive.google.com/open?id=1kjLaYC_KJUlltm-iAzgF5VmHgb7Uer0z) to practice the processing techniques you learned above!
"""